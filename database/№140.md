

Как интерпретировать Shapley (SHAP) values?

---

SHAP values показывают, какой вклад каждый признак внёс в предсказание модели для конкретного объекта по сравнению с базовым значением.

Интерпретация:
- положительное SHAP-значение — признак увеличил предсказание
- отрицательное — признак уменьшил предсказание
- сумма SHAP-значений всех признаков равна разнице между предсказанием и базовым уровнем
    
SHAP основан на идее справедливого распределения вклада и учитывает все возможные комбинации признаков, поэтому на практике используется в виде приближений.

SHAP отвечает на вопрос: “кто и на сколько повлиял на это предсказание?”

---

#lvl_3